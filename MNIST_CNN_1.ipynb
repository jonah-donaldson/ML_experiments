{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNZGPmH4wX3YI3fyTumoWN5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Practical Machine Learning for Physicists\n","## Coursework C -- Part 1"],"metadata":{"id":"R5qvi7y3Ddfy"}},{"cell_type":"markdown","source":["### Task 1:\n","Design, implement and test a neural network utilising a single convolutional layer (use as many other non convolutional layers as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using a single convolutional layer?\n","\n","### Task 2:\n","Design, implement and test a neural network utitlising multiple convolutional layers (again use as many other non convolutinal laters as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using as many convolutional layers as you like?\n","\n","#### Practicalities\n","You should use this notebook for your work and upload it to Moodle. You are expected to use TensorFlow and Keras to complete these takss. The notebook should be self-contained and able to be executed if necessary. Marks will be awarded for (roughly equally weighted):\n","- Overall notebook clarity (both in terms of good coding practice and coherent discussion)\n","- Network performance (how well does your classifier do?)\n","- Network efficiency (how does your network compare to the optimum networks for this task?)\n","- Network training (do you do a good job of traning your network?)\n"],"metadata":{"id":"drw5iBsXDZ5k"}},{"cell_type":"code","source":["#Import libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","\n","import matplotlib.style\n","import matplotlib as mpl\n","\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUMNumooYHPK","executionInfo":{"status":"ok","timestamp":1706794324945,"user_tz":0,"elapsed":2989,"user":{"displayName":"Jonah Donaldson","userId":"04540935030243818714"}},"outputId":"1c4c5f4f-c351-4d58-9aed-2210390aa583"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.15.0\n"]}]},{"cell_type":"code","source":["mnist = keras.datasets.mnist #data set of handwritten numbers\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data() #Note each data point/pixl can take a value in range 0-255\n","\n","print(train_images.shape) #Shape of training images\n","print(train_labels.shape) #Number of training images\n","\n","train_images=train_images/255 #normalise data\n","test_images=test_images/255"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZdgy7meE95i","executionInfo":{"status":"ok","timestamp":1706794325359,"user_tz":0,"elapsed":418,"user":{"displayName":"Jonah Donaldson","userId":"04540935030243818714"}},"outputId":"6cb44fc7-57fb-476a-a35a-584b06b2fef4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","(60000, 28, 28)\n","(60000,)\n"]}]},{"cell_type":"code","source":["#Part 1\n","\n","model = keras.models.Sequential() #Add convolution layer and pooling\n","model.add(keras.layers.Conv2D(28, (4, 5), activation='relu', input_shape=(28, 28, 1)))\n","model.add(keras.layers.MaxPooling2D((4,4)))\n","\n","model.add(keras.layers.Flatten()) #Flatten and get output\n","model.add(keras.layers.Dense(14, activation='relu'))\n","model.add(keras.layers.Dense(10))"],"metadata":{"id":"VaCasxmjE-ep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary() #Sanity check model"],"metadata":{"id":"j9qllKETbH3U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706794336103,"user_tz":0,"elapsed":272,"user":{"displayName":"Jonah Donaldson","userId":"04540935030243818714"}},"outputId":"04f056d0-d356-40ee-9cde-31f8560e6bc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 25, 24, 28)        588       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 6, 6, 28)          0         \n"," D)                                                              \n","                                                                 \n"," flatten (Flatten)           (None, 1008)              0         \n","                                                                 \n"," dense (Dense)               (None, 14)                14126     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                150       \n","                                                                 \n","=================================================================\n","Total params: 14864 (58.06 KB)\n","Trainable params: 14864 (58.06 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#Compile and train model\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy']) #Compiles model with adam optimiser\n","\n","history = model.fit(train_images, train_labels,batch_size=200,epochs=15,\n","                    validation_data=(test_images, test_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0P3mkryNbK8r","outputId":"5e80e76b-c064-46da-bc1b-f7b315adb831","executionInfo":{"status":"ok","timestamp":1706787799131,"user_tz":0,"elapsed":21054,"user":{"displayName":"Jonah Donaldson","userId":"04540935030243818714"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","300/300 [==============================] - 2s 5ms/step - loss: 0.5696 - accuracy: 0.8403 - val_loss: 0.1805 - val_accuracy: 0.9520\n","Epoch 2/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9556 - val_loss: 0.1053 - val_accuracy: 0.9687\n","Epoch 3/15\n","300/300 [==============================] - 1s 5ms/step - loss: 0.1034 - accuracy: 0.9701 - val_loss: 0.0784 - val_accuracy: 0.9756\n","Epoch 4/15\n","300/300 [==============================] - 2s 5ms/step - loss: 0.0817 - accuracy: 0.9764 - val_loss: 0.0699 - val_accuracy: 0.9784\n","Epoch 5/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0708 - accuracy: 0.9793 - val_loss: 0.0585 - val_accuracy: 0.9817\n","Epoch 6/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.0550 - val_accuracy: 0.9829\n","Epoch 7/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9831 - val_loss: 0.0624 - val_accuracy: 0.9783\n","Epoch 8/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0552 - val_accuracy: 0.9816\n","Epoch 9/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.0489 - val_accuracy: 0.9837\n","Epoch 10/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.0447 - val_accuracy: 0.9852\n","Epoch 11/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.0423 - val_accuracy: 0.9861\n","Epoch 12/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.0516 - val_accuracy: 0.9830\n","Epoch 13/15\n","300/300 [==============================] - 1s 5ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.0411 - val_accuracy: 0.9865\n","Epoch 14/15\n","300/300 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9888 - val_loss: 0.0483 - val_accuracy: 0.9843\n","Epoch 15/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 0.0437 - val_accuracy: 0.9857\n"]}]},{"cell_type":"code","source":["#Run trained model on test set\n","test_loss,test_acc = model.evaluate(test_images,  test_labels, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"urfUtFIskXT5","executionInfo":{"status":"ok","timestamp":1706786112040,"user_tz":0,"elapsed":932,"user":{"displayName":"Jonah Donaldson","userId":"04540935030243818714"}},"outputId":"d674a420-5eb6-46e7-c540-4450b3857874"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 - 1s - loss: 0.0464 - accuracy: 0.9850 - 718ms/epoch - 2ms/step\n"]}]},{"cell_type":"code","source":["# Part 2\n","\n","model2 = keras.models.Sequential() #Add convolution layer and pooling\n","model2.add(keras.layers.Conv2D(28, (5, 6), activation='relu', input_shape=(28, 28, 1)))\n","model2.add(keras.layers.MaxPooling2D((3,3)))\n","\n","model2.add(keras.layers.Conv2D(32, (5, 6), activation='relu')) #added extra convolution layer and pool\n","model2.add(keras.layers.MaxPooling2D((2, 2)))\n","\n","model2.add(keras.layers.Flatten())\n","model2.add(keras.layers.Dense(28, activation='relu'))\n","model2.add(keras.layers.Dense(10))"],"metadata":{"id":"RzXFy6vXfaKg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qwn3rqApiXU9","executionInfo":{"status":"ok","timestamp":1706787517515,"user_tz":0,"elapsed":4,"user":{"displayName":"Jonah Donaldson","userId":"04540935030243818714"}},"outputId":"9451c5c7-ebd6-4a19-a771-8fb81bd40a8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_26\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_51 (Conv2D)          (None, 24, 23, 28)        868       \n","                                                                 \n"," max_pooling2d_51 (MaxPooli  (None, 8, 7, 28)          0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_52 (Conv2D)          (None, 4, 2, 32)          26912     \n","                                                                 \n"," max_pooling2d_52 (MaxPooli  (None, 2, 1, 32)          0         \n"," ng2D)                                                           \n","                                                                 \n"," flatten_26 (Flatten)        (None, 64)                0         \n","                                                                 \n"," dense_52 (Dense)            (None, 28)                1820      \n","                                                                 \n"," dense_53 (Dense)            (None, 10)                290       \n","                                                                 \n","=================================================================\n","Total params: 29890 (116.76 KB)\n","Trainable params: 29890 (116.76 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model2.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","history = model2.fit(train_images, train_labels,batch_size=200,epochs=15,\n","                    validation_data=(test_images, test_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juSxkvrNjR3k","outputId":"952260a1-4eb2-4ccc-d2d2-945b0d4ebbf0","executionInfo":{"status":"ok","timestamp":1706787539922,"user_tz":0,"elapsed":22110,"user":{"displayName":"Jonah Donaldson","userId":"04540935030243818714"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","300/300 [==============================] - 3s 5ms/step - loss: 0.4641 - accuracy: 0.8645 - val_loss: 0.1086 - val_accuracy: 0.9671\n","Epoch 2/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9714 - val_loss: 0.0708 - val_accuracy: 0.9784\n","Epoch 3/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9800 - val_loss: 0.0579 - val_accuracy: 0.9818\n","Epoch 4/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9836 - val_loss: 0.0433 - val_accuracy: 0.9853\n","Epoch 5/15\n","300/300 [==============================] - 1s 5ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.0383 - val_accuracy: 0.9876\n","Epoch 6/15\n","300/300 [==============================] - 2s 6ms/step - loss: 0.0396 - accuracy: 0.9877 - val_loss: 0.0339 - val_accuracy: 0.9888\n","Epoch 7/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 0.0306 - val_accuracy: 0.9903\n","Epoch 8/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.0295 - val_accuracy: 0.9906\n","Epoch 9/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.0297 - val_accuracy: 0.9903\n","Epoch 10/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0320 - val_accuracy: 0.9887\n","Epoch 11/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.0283 - val_accuracy: 0.9902\n","Epoch 12/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0303 - val_accuracy: 0.9902\n","Epoch 13/15\n","300/300 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0310 - val_accuracy: 0.9892\n","Epoch 14/15\n","300/300 [==============================] - 2s 5ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0308 - val_accuracy: 0.9900\n","Epoch 15/15\n","300/300 [==============================] - 2s 5ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0293 - val_accuracy: 0.9902\n"]}]},{"cell_type":"code","source":["#Run trained model on test set\n","test_loss,test_acc = model2.evaluate(test_images,  test_labels, verbose=2)"],"metadata":{"id":"tDjFUpaDjlRl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706787546644,"user_tz":0,"elapsed":925,"user":{"displayName":"Jonah Donaldson","userId":"04540935030243818714"}},"outputId":"336f47e6-eb8a-4948-c792-83289e709bd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 - 1s - loss: 0.0293 - accuracy: 0.9902 - 698ms/epoch - 2ms/step\n"]}]},{"cell_type":"code","source":["#PART 2"],"metadata":{"id":"35KoTSVUqbQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#A big messy function to do the training\n","# model -- our keras neural model autoencoder\n","# image_generator -- a function to generate random images for the training (see below for examples)\n","# img_size -- the size of our image in pixels\n","# batchsize -- the number of images to include in each training batch\n","# steps -- the number of steps taken in the training\n","#\n","# returns an array of the costs\n","def generate_and_train(model,image_generator,img_size,batchsize,steps):\n","\n","    #Generate an array of the numbers 1 to img_size and create a meshgrid from them\n","    pixels=np.linspace(-1,1,img_size)\n","    x,y=np.meshgrid(pixels,pixels)\n","\n","    #Now create a test image using 1 call to image_generator\n","    #y_test=np.zeros([1,pixels,pixels,1])\n","    #y_test[:,:,:,0]=image_generator(1,x,y)\n","\n","    #Now create the empty arrays for the images and cost\n","    y_in=np.zeros([batchsize,img_size,img_size,1])\n","    y_target=np.zeros([batchsize,img_size,img_size,1])\n","    cost=np.zeros(steps)\n","\n","    #Loop through the steps, get a random batch of samples, train the model, repeat\n","    for k in range(steps):\n","        # produce samples:\n","        y_in[:,:,:,0]=image_generator(batchsize,x,y)\n","        y_target=np.copy(y_in) # autoencoder wants to reproduce its input!\n","\n","        # do one training step on this batch of samples:\n","        cost[k]=model.train_on_batch(y_in,y_target)\n","\n","    return cost,y_target\n","\n","def get_test_image(image_generator,img_size):\n","    #Generate an array of the numbers 1 to img_size and create a meshgrid from them\n","    pixels=np.linspace(-1,1,img_size)\n","    x,y=np.meshgrid(pixels,pixels)\n","\n","    #Now create a test image using 1 call to image_generator\n","    y_test=np.zeros([1,img_size,img_size,1])\n","    y_test[:,:,:,0]=image_generator(1,x,y)\n","    return y_test\n","\n","# A function to generate and plot a single test image and the output of our model\n","# only to be called after training the model\n","def plot_test_image(model,image_generator,img_size):\n","    #Get random test image\n","    y_test=get_test_image(image_generator,img_size)\n","\n","    #Create the output image\n","    y_test_out=model.predict_on_batch(y_test)\n","    fig, ax = plt.subplots(1,2)\n","    ax[0].imshow(y_test[0,:,:,0],origin='lower')\n","    ax[0].set_title(\"Input\")\n","    ax[1].imshow(y_test_out[0,:,:,0],origin='lower')\n","    ax[1].set_title(\"Output\")\n","\n","def print_layers(network, y_in):\n","    \"\"\"\n","    Call this on some test images y_in, to get a print-out of\n","    the layer sizes. Shapes shown are (batchsize,pixels,pixels,channels).\n","    After a call to the visualization routine, y_target will contain\n","    the last set of training images, so you could feed those in here.\n","    \"\"\"\n","    layer_features=get_layer_activations(network,y_in)\n","    #print(layer_features)\n","    for idx,feature in enumerate(layer_features):\n","        s=np.shape(feature)\n","        print(\"Layer \"+str(idx)+\": \"+str(s[1]*s[2]*s[3])+\" neurons / \", s)\n","\n","def get_layer_activation_extractor(network):\n","    #print(network.inputs)\n","    #for layer in network.layers:\n","    #    print(layer.output)\n","    return(keras.Model(inputs=network.inputs,\n","                            outputs=[layer.output for layer in network.layers]))\n","\n","def get_layer_activations(network, y_in):\n","    \"\"\"\n","    Call this on some test images y_in, to get the intermediate\n","    layer neuron values. These are returned in a list, with one\n","    entry for each layer (the entries are arrays).\n","    \"\"\"\n","    extractor=get_layer_activation_extractor(network)\n","    #print(extractor)\n","    layer_features = extractor(y_in)\n","    return layer_features"],"metadata":{"id":"ui6pWRD6ZAJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A simple image generator that returns an array of batchsize images\n","# each image has a size of x * y pixels\n","# in this image each image has a randomly placed circle (and the circle is of random size)\n","def circle_generator(batchsize,x,y):\n","    R=np.random.uniform(size=batchsize)\n","    x0=np.random.uniform(size=batchsize,low=-1,high=1)\n","    y0=np.random.uniform(size=batchsize,low=-1,high=1)\n","    return( 1.0*((x[None,:,:]-x0[:,None,None])**2 + (y[None,:,:]-y0[:,None,None])**2 < R[:,None,None]**2) )"],"metadata":{"id":"epTNypl9ZEaA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Task 1\n","model=keras.models.Sequential()\n","#Convolutional Layer 1\n","model.add(keras.layers.Conv2D(26, 6, input_shape=(None, None, 1), activation=\"relu\", padding='same'))\n","model.add(keras.layers.AveragePooling2D(pool_size=(3, 3), padding='same'))  # down\n","\n","# Convolutional Layer 2\n","model.add(keras.layers.Conv2D(13, 6, activation=\"relu\", padding='same'))\n","model.add(keras.layers.AveragePooling2D(pool_size=(3, 3), padding='same'))  # down\n","\n","# Bottleneck Layer\n","model.add(keras.layers.Conv2D(1, 3, activation=\"relu\", padding='same')) #Bottleneck\n","\n","# Up-sampling Layer 1\n","model.add(keras.layers.UpSampling2D(size=(3, 3)))  # up\n","model.add(keras.layers.Conv2D(13, 6, activation=\"relu\", padding='same'))\n","\n","# Up-sampling Layer 2\n","model.add(keras.layers.UpSampling2D(size=(3, 3)))  # up\n","model.add(keras.layers.Conv2D(26, 6, activation=\"relu\", padding='same'))\n","\n","# Output Layer\n","model.add(keras.layers.Conv2D(1, 12, activation=\"relu\", padding='same'))\n","\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","model.summary()"],"metadata":{"id":"YgyQFBDJZGiK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model training\n","steps=1000\n","cost,y_target=generate_and_train(model,circle_generator,img_size=27,batchsize=30,steps=steps)\n","#Plot the cost\n","fig, ax = plt.subplots()\n","stepArray=np.arange(steps)\n","ax.plot(stepArray,cost,linewidth=3)\n","ax.set_xlabel(\"Step Number\")\n","ax.set_ylabel(\"Cost\")\n","\n","print_layers(model,y_target)"],"metadata":{"id":"iJkurglzZIkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_test_image(model,circle_generator,30)\n","print(min(cost))"],"metadata":{"id":"Kk96LPaxZNqX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Task 2\n","model2=keras.models.Sequential()\n","#Convolutional Layer 1\n","model2.add(keras.layers.Conv2D(26, 6, input_shape=(None, None, 1), activation=\"relu\", padding='same'))\n","model2.add(keras.layers.AveragePooling2D(pool_size=(3, 3), padding='same'))  # down\n","\n","# Convolutional Layer 2\n","model2.add(keras.layers.Conv2D(13, 6, activation=\"relu\", padding='same'))\n","model2.add(keras.layers.AveragePooling2D(pool_size=(3, 3), padding='same'))  # down\n","\n","# Bottleneck Layer\n","model2.add(keras.layers.Conv2D(1, 3, activation=\"relu\", padding='same')) #Bottleneck\n","model2.add(keras.layers.AveragePooling2D(pool_size=(1, 3), padding='same'))\n","\n","# Up-sampling Layer 1\n","model2.add(keras.layers.UpSampling2D(size=(3, 9)))  # up\n","model2.add(keras.layers.Conv2D(13, 6, activation=\"relu\", padding='same'))\n","\n","# Up-sampling Layer 2\n","model2.add(keras.layers.UpSampling2D(size=(3, 3)))  # up\n","model2.add(keras.layers.Conv2D(26, 6, activation=\"relu\", padding='same'))\n","\n","# Output Layer\n","model2.add(keras.layers.Conv2D(1, 12, activation=\"relu\", padding='same'))\n","\n","model2.compile(loss='mean_squared_error', optimizer='adam')\n","model2.summary()"],"metadata":{"id":"6BtZXLiCZPWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Model 2 training\n","steps=1000\n","cost2,y_target=generate_and_train(model2,circle_generator,img_size=27,batchsize=30,steps=steps)\n","#Plot the cost\n","fig, ax = plt.subplots()\n","stepArray=np.arange(steps)\n","ax.plot(stepArray,cost,linewidth=3)\n","ax.set_xlabel(\"Step Number\")\n","ax.set_ylabel(\"Cost\")\n","\n","print_layers(model2,y_target)"],"metadata":{"id":"FHb123xCZRhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_test_image(model2,circle_generator,30)\n","print(min(cost2))"],"metadata":{"id":"HrRV8c_3ZUub"},"execution_count":null,"outputs":[]}]}